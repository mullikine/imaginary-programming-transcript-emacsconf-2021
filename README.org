* Imaginary Programming transcript for EmacsConf 2021
+ Talk URL :: https://emacsconf.org/2021/talks/imaginary/

* Transcript
Dear fellow free software enthusiasts, it's a real honor to present for EmacsConf on the topic of Imaginary Programming.

My goal is to introduce people to a new style of
programming that I believe will be mainstream
within the year, even if it goes by other names. 

This is certainly not the only way that LMs can be applied to
programming but I think this is an elegant way
to do it. I'll demonstrate using my library
for imaginary programming, =ùëñŒª.el= and I hope
that it is enlightening.

IP works currently thanks to another new field in AI
namely 'prompt engineering', which itself has
only been around for a couple of years now,
but IP is not prompt engineering. We could,
for instance, have humans behind the scenes
doing the inference for us while employing
=ieval=, =imacro= or =ilist=.

IP is not a conventional programming paradigm
yet, but I think that it is going to quickly
become so.

# since people who understand the way GitHub's
# Copilot works will be quickly dissatisfied
# with the limiting, opaque and functions that it
# and other magical tooling provides; We are
# engineers, not consumers and we want full
# control over our computers.

# This is due to the compelling, if not
# controversial, recent advances in the
# capabilities of large LMs such as GPT-3, since
# they provide programmers with more efficient
# means to write software.

Without further ado, imaginary programming is what you get when you
combine LMs with programming.

# =reversible programming= is another paradigm I think also become more mainstream due to language models.

# I think it's as intrinsic to programming as imaginary numbers, fractions or negative numbers are intrinsic to algebra.

You would find ùëñŒª useful if you want to, for example:
- from within the comfort of emacs lisp:
  - establish specific places in your code you are ok with using inference instead of computation.
  - use AI imagination to help you write concrete code.
  - interactively regenerate specific parts of your code when you revisit it.
  - frame complicated or intractable problems as tasks for the AI to implement/deal with instead of yourself.
  - mock parts of your code

If you have trained a language model on your own code:
- use imaginary reflection

** Why the word *imaginary*?
*** Reason 1: Advances in Neuroscience-inspired AI towards computers that imagine
+ Google DeepMind's Demis Hassabis :: https://youtu.be/0X-NdPtFKq0?t=1559

**** AGI (Artificial General Intelligence)
- Imagination is a core topic, overlooked
  - [[calibre:Artificial Intelligence. A Modern Approach]]

- Memory
- Attention
- Concepts
- Planning
- Navigation
- Imagination

**** Neuroscience
- Memory, Imagination, and Predicting the Future A Common Brain Mechanism?
  - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4232337/

***** Hippocampus
- The hippocampus is vital for episodic memory.
- Probably also vital for imagination.

If memory works as a reconstructive process
then if we think about imagination as being a
similar process but in this case it's a
constructive process if we think of memory as
trying to put your components that you have
together in a way that your brain thinks
looks and judges as familiar perhaps
creativity's that is the converse of that.

#+BEGIN_SRC text -n :async :results verbatim code
  creativity
  imagination
      The converse of memory.
  
      https://youtu.be/0X-NdPtFKq0?t=1559
      
      You're still bringing together those
      components but now you're trying to create
      something novel that actually your brain
      judges as unfamiliar.
  
      If memory is heavily depend on the
      hippocampus then maybe imagination is also
      a very heavily dependent on the same brain
      structure and the same processes.
  
      We now know that it is.
  
  hippocampus
      [#neuroscience]
  
      Involved with is reconstructing that
      pulling all those parts together into a
      coherent whole which then is recognized by
      the rest of your brain as actually an
      episodic memory.
#+END_SRC

**** Beam-search on LLMs
This algorithm is used to probe possible
generations with an objective. Coherent and
surprising generations may be given higher
scores.

This is essentially searching for novel and
surprising, yet 'coherent' text -- i.e.
imagining.

*** Reason 2: Similarities to imaginary numbers

** Information
https://youtu.be/sMb00lz-IfE?t=66

Information is about order.

*** Randomness
Pure information is purely random, but it's
difficult to learn and recognise patterns, the
more information rich it is.

https://youtu.be/sMb00lz-IfE?t=269