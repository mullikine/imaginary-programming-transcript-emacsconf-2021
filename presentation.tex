% Created 2021-11-07 Sun 14:26
% Intended LaTeX compiler: pdflatex
\documentclass[presentation]{beamer}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usetheme[height=20pt]{Rochester}
\author{Shane Mulligan \\  }
\date{\textit{<2021-03-01 Mon>}}
\title{emacsconf 2021\ldots{} \\   \emph{\alert{Imaginary Programming with Emacs}} \\  }
\hypersetup{
 pdfauthor={Shane Mulligan \\  },
 pdftitle={emacsconf 2021\ldots{} \\   \emph{\alert{Imaginary Programming with Emacs}} \\  },
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.0.50 (Org mode 9.3.6)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section{Presentation}
\label{sec:org05ae142}
\begin{frame}[label={sec:orgd1fdd78}]{Following along}
\begin{block}{Repositories for following along}
{\tiny
\begin{center}
\begin{tabular}{l}
\url{http://github1s.com/semiosis/pen.el}\\
\url{http://github1s.com/semiosis/prompts}\\
\url{https://mullikine.github.io/posts/imaginary-programming-with-gpt-3/}\\
\href{http://github.com/semiosis/glossaries-gh/blob/master/imaginary-programming.txt}{imaginary programming glossary}\\
\href{http://github.com/semiosis/glossaries-gh/blob/master/imaginary-computing.txt}{imaginary computing glossary}\\
\href{http://github.com/semiosis/glossaries-gh/blob/master/semiosis-protocol.txt}{semiosis protocol glossary}\\
\href{http://github.com/semiosis/glossaries-gh/blob/master/pen.el.txt}{Pen.el glossary}\\
\href{https://arxiv.org/abs/2107.13586}{https://arxiv.org/abs/2107.13586 Pre-train, Prompt, and Predict}\\
\href{http://github1s.com/mullikine/imaginary-programming-transcript-emacsconf-2021}{talk transcript}\\
\end{tabular}
\end{center}
}
\end{block}
\end{frame}

\section{Imaginary Programming with Emacs}
\label{sec:orgbca2e59}
\begin{frame}[label={sec:org731c6d8},fragile]{Imaginary Programming (emacsconf 2021)}
 \begin{block}{Objectives}
\begin{itemize}
\item Explain Imaginary Computing
\begin{itemize}
\item AI imagination
\item Discussing AI-generated artwork with an AI
\item Intelligent NFTs
\item Imaginary Web
\begin{itemize}
\item Paracosm vs Metaverse
\end{itemize}
\end{itemize}
\item Explain Philosophy
\begin{itemize}
\item Simulacra and Science Fiction
\item Truth (epistemology and alethiology)
\item Structuralism: Language based on sign relations
\end{itemize}
\item Demo Imaginary Programming
\begin{itemize}
\item Demonstrate \texttt{ilambda.el}
\end{itemize}
\end{itemize}
\end{block}
\end{frame}

\section{Imaginary Computing}
\label{sec:orgb184770}
\begin{frame}[label={sec:orged36ca7}]{AI Imagination}
\begin{block}{Language Models is programming for AIs}
LMs are our best friends in the AI model
menagerie because they make things
intelligible -- by understanding our textual
languages.
\end{block}

\begin{block}{Research}
\begin{itemize}
\item \href{https://www.youtube.com/watch?v=d-bvsJWmqlc}{Demis Hassabis: creativity and AI}
\end{itemize}
\end{block}
\end{frame}

\section{Imaginary Computing}
\label{sec:orgde59f4f}
\begin{frame}[label={sec:org2691685}]{Emacs as the command-center for prompting}
\begin{block}{Example: AI Art described by AI}
I use AlephAlpha’s multimodal LM to generate
alttext for the eww web browser. This is in
order to keep websites textual.

\begin{itemize}
\item \href{https://mullikine.github.io/posts/alephalpha-for-alttext/}{AlephAlpha for alttext; Browsing the paracosm // Bodacious Blog}
\item \href{https://mullikine.github.io/posts/describing-melee-s-paintings-with-alephalpha/}{Describing Melee's Paintings with AlephAlpha // Bodacious Blog}
\end{itemize}
\end{block}
\end{frame}

\section{Imaginary Computing}
\label{sec:org283e8f8}
\begin{frame}[label={sec:orgf3d0240},fragile]{Blockchain}
 \begin{block}{Intelligent NFTs}
An \texttt{NFT} is like a trading card, or piece of media, and as people.

An \texttt{iNTF}, however, also contains a prompt and associated language model, which is intended to interpret the prompt.
\begin{itemize}
\item \url{https://alethea.ai/}
\end{itemize}

To understand what a prompt is, please see my
previous presentation, or read "Pretrain,
Prompt and Predict".

\begin{itemize}
\item \href{https://mullikine.github.io/posts/creating-a-playground-for-gpt-3-in-emacs/}{Creating a playground for GPT-3 in emacs // Bodacious Blog}
\end{itemize}
\end{block}
\end{frame}

\section{Imaginary Computing}
\label{sec:org74215be}
\begin{frame}[label={sec:orgf5b4d5e}]{Potential Dystopia}
\begin{block}{Information bubbles}
\begin{itemize}
\item \href{https://www.youtube.com/watch?v=Ut7JlPeGNyM}{Captain Bible in the Dome of Darkness gameplay \{PC Game, 1994\} - YouTube}
\end{itemize}
\end{block}

\begin{block}{Capitalism for your imagination}
\begin{itemize}
\item They will take your imagination too
\item Microsoft
\begin{itemize}
\item \href{https://www.marktechpost.com/2021/11/06/microsoft-ai-introduces-turing-bletchley-a-2-5-billion-parameter-universal-image-language-representation-model-t-uilr/}{MS models that reify your imagination}
\item The evil twin on AlephAlpha.
\end{itemize}
\item Facebook / Meta
\begin{itemize}
\item \href{https://twitter.com/Meta/status/1456269728687689738?ref\_src=twsrc\%5Egoogle\%7Ctwcamp\%5Eserp\%7Ctwgr\%5Etweet}{tweet - Enter a world of imagination with Meta}
\end{itemize}
\end{itemize}
\end{block}
\end{frame}

\section{Imaginary Computing}
\label{sec:org57b9e3e}
\begin{frame}[label={sec:org115b929},fragile]{Paracosm vs Metaverse}
 \begin{block}{Imaginary Web}
The imaginary web is a network of paracosms
and metaverses.

\begin{verbatim}
1  imaginary internet
2  imaginary web
3      An imaginary world-wide-web is an
4      analog of the World-Wide-Web imagined by a
5      language model.
\end{verbatim}
\end{block}

\begin{block}{emacs}
An imaginary-web browser for emacs.

\begin{itemize}
\item \url{https://semiosis.github.io/looking-glass/}
\end{itemize}
\end{block}
\end{frame}

\begin{frame}[label={sec:orga1cd71e}]{Paracosm vs Metaverse}
\begin{block}{Definitions}
\begin{itemize}
\item Paracosm
\begin{itemize}
\item Privacy
\item Personal truth
\item Freedom of imagination
\end{itemize}
\item Metaverse
\begin{itemize}
\item Getting cozy with Mark Zuckerberg's imaginarium, an intellectual prison
\end{itemize}
\end{itemize}
\end{block}
\end{frame}

\section{Preliminaries}
\label{sec:orgbd89537}
\subsection{GPT-3}
\label{sec:org59432d6}
\begin{frame}[label={sec:orgd92c40f},fragile]{Text Generator}
 \begin{block}{Background knowledge}
{\footnotesize
\begin{itemize}
\item \texttt{GPT-3} is a \texttt{seq2seq} model (a text generator)
\begin{itemize}
\item It's stochastic but can be configured to be deterministic.
\end{itemize}
\end{itemize}
}
\end{block}

\begin{block}{Key concepts}
{\footnotesize
\begin{itemize}
\item prompt,
\item completion, and
\item tokens
\end{itemize}
}
\end{block}

\begin{block}{Limitations}
{\footnotesize
Combined, the text prompt and generated
completion must be below 2048 tokens (roughly
\textasciitilde{}1500 words).

\begin{description}
\item[{context-stuffing}] With only 2048 tokens, you need to make
use of your real estate by providing
instructions and making implicit
information explicit.
\end{description}
}
\end{block}
\end{frame}

\subsection{A new programming paradigm}
\label{sec:org1fa4441}
\begin{frame}[label={sec:org81a310a},fragile]{Prompt Engineering}
 \begin{block}{Characteristics}
{\footnotesize
\begin{itemize}
\item declarative, like \texttt{html}
\item stochastic, like \texttt{problog}
\item Unlocks new types of applications
\item Speeds up development
\end{itemize}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgf3c6295},fragile]{Some prompts I've made}
 \begin{block}{\texttt{generate-vim-command.prompt}}
{\footnotesize
\begin{verbatim}
 1  Vim
 2  
 3  Insert "Q: " at the start of the line
 4  :%s/^/Q: /g.
 5  ###
 6  Remove whitespace from the start of each line
 7  :%s/^\s*/\1/g
 8  ###
 9  Join each line with the next line
10  :1,$j
11  ###
12  Make all occurrences of Steve lowercase
13  :%s/Steve/steve/g
14  ###
15  <1>
\end{verbatim}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:org9e12b50}]{Tasks suitable for GPT-3}
\begin{block}{Classification}
\begin{itemize}
\item Tweet Sentiment
\item Company categorization
\item Labeling parts of speech
\end{itemize}

{\footnotesize
\begin{itemize}
\item \url{http://github.com/semiosis/prompts/blob/master/prompts/tweet-sentiment-classifier.prompt}
\item \url{http://github.com/semiosis/prompts/blob/master/prompts/keyword-extraction.prompt}
\end{itemize}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:org4fb78aa}]{Tasks suitable for GPT-3}
\begin{block}{Generation}
\begin{itemize}
\item Idea Generator
\end{itemize}

Come up with silly inventions.

\begin{center}
\includegraphics[width=.9\linewidth]{./silly-inventions.png}
\end{center}
\end{block}
\end{frame}

\begin{frame}[label={sec:org20458b6}]{Tasks suitable for GPT-3}
\begin{block}{Conversation}
\begin{itemize}
\item Q\&A agent
\item Sarcastic chatbot
\end{itemize}

{\footnotesize
\url{http://github.com/semiosis/prompts/blob/master/prompts/sarcastic-response.prompt}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:org8467f36},fragile]{Design patterns}
 Taken from Prompt Design 101.

These are manual techniques which should be
encoded in a DSL when generating prompts.

\begin{block}{1. Reflective description of the task}
State what the prompt does at the start.

At the start of the example we state in plain
language what the classifier does:

\begin{verbatim}
1  This is a tweet sentiment classifier.
\end{verbatim}

By stating this up front, it helps the API
understand much more quickly what the goal of
the response is supposed to be and you’ll end
needing to provide fewer examples.
\end{block}
\end{frame}

\begin{frame}[label={sec:org12f7528},fragile]{Design patterns}
 Taken from Prompt Design 101.

These are manual techniques which should be
encoded in a DSL when generating prompts.

\begin{block}{2. Use separators between examples}
Example: \texttt{\#\#\#}.

You can use other characters or line breaks,
but \texttt{\#\#\#} works pretty consistently and is
also an easy to use stop sequence.

Whatever separator you use, make sure that
it’s clear to the API where an example starts
and stops.
\end{block}
\end{frame}

\begin{frame}[label={sec:org24d6e74},fragile]{Design patterns}
 Taken from Prompt Design 101.

These are manual techniques which should be
encoded in a DSL when generating prompts.

\begin{block}{3. Mutiplexer Part 1}
Make a prompt more efficient / cheaper.

Design it to generate multiple results from
one API call.

{\tiny
\begin{verbatim}
 1  This is a tweet sentiment classifier
 2  Tweet: "I loved the new Batman movie!"
 3  Sentiment: Positive
 4  ###
 5  Tweet: "I hate it when my phone battery dies"
 6  Sentiment: Negative
 7  ###
 8  Tweet: "My day has been 👍"
 9  Sentiment: Positive
10  ###
11  Tweet: "This is the link to the article"
12  Sentiment: Neutral
13  ###
14  Tweet text
\end{verbatim}

}
\end{block}
\end{frame}

\begin{frame}[label={sec:org39ef122},fragile]{Design patterns}
 Taken from Prompt Design 101.

These are manual techniques which should be
encoded in a DSL when generating prompts.

\begin{block}{3. Mulitplexer Part 2}
{\tiny
\begin{verbatim}
 1  1. "I loved the new Batman movie!"
 2  2. "I hate it when my phone battery dies"
 3  3. "My day has been 👍"
 4  4. "This is the link to the article"
 5  5. "This new music video blew my mind"
 6  
 7  Tweet sentiment ratings:
 8  1: Positive
 9  2: Negative
10  3: Positive
11  4: Neutral
12  5: Positive
13  
14  ###
15  Tweet text
\end{verbatim}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgcfc73cc},fragile]{Design patterns}
 Taken from Prompt Design 101.

These are manual techniques which should be
encoded in a DSL when generating prompts.

\begin{block}{3. Multiplexer Part 3}
{\footnotesize
\begin{verbatim}
1  "I can't stand homework"
2  "This sucks. I'm bored 😠"
3  "I can't wait for Halloween!!!"
4  "My cat is adorable ❤️❤️"
5  "I hate chocolate"
6  Tweet sentiment ratings:
7  1.
\end{verbatim}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:org2233735}]{Techniques}
\begin{block}{Query Reformulation}
\url{https://www.sciencedirect.com/topics/computer-science/query-reformulation}

You can improve the quality of the responses
by making a longer more diverse list in your
prompt.

One way to do that is to start off with one
example, let the API generate more and select
the ones that you like best and add them to
the list.

A few more high-quality variations can
dramatically improve the quality of the
responses.
\end{block}
\end{frame}

\section{Explanations}
\label{sec:org4335251}
\subsection{Using \texttt{pen.el}}
\label{sec:org96219a4}
\begin{frame}[label={sec:org746f91a},fragile]{\texttt{pen.el}}
 \begin{block}{\texttt{pen.el}: Prompt Engineering in emacs}
{\footnotesize
\texttt{pen.el} facilitates the creation,
development, discovery and usage of prompts to
a Language Model such as GPT-3.

\begin{itemize}
\item Create elisp functions based on GPT-3 prompts
\item Chain GPT-3 queries together using keyboard macros and functions
\item Interactively query, generate and transfrom both prose and code
\item Use GPT-3 as a search engine within emacs
\end{itemize}
}
\end{block}
\end{frame}

\subsection{Using \texttt{pen.el}}
\label{sec:org8ea01ed}
\begin{frame}[label={sec:org812c351},fragile]{\texttt{pen.el}}
 \begin{block}{\texttt{pen.el} modes Part 1}
{\footnotesize
\uline{\alert{Prompt-Engineering Minor Mode}}

\texttt{prompt-engineering-mode} is a global minor
mode for emacs that provides keybindings for
creating and executing prompts generally
across emacs.

\uline{\alert{Prompt Description Major Mode}}

\texttt{prompt-description-mode} is a major mode for
editing \texttt{.prompt} files.

The \texttt{.prompt} file format is based on YAML and
an associated schema, which defines the keys
which are expected.
}
\end{block}
\end{frame}

\subsection{Using \texttt{pen.el}}
\label{sec:org5381eae}
\begin{frame}[label={sec:org6f74229},fragile]{\texttt{pen.el}}
 \begin{block}{\texttt{pen.el} modes Part 2}
{\footnotesize
\uline{\alert{Pen Messenger Minor Mode}}

\texttt{pen-messenger-mode} is a minor mode for
enhancing an emacs-based messenger client with
GPT-3 capabilities, such as emoji generation.

\uline{\alert{Pen Conversation Mode}}

\texttt{prompt-conversation-mode} is a major mode designed to facilitate
ongoing conversation with a prompt-based GPT-3 chatbot.

\uline{\alert{GPT-3 Training Mode}}

The goal of this mode is to facilitate the
workflow of training on OpenAI's API.
}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgbf1fce7},fragile]{Prompt YAML format Part 1}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
 1  title: "meeting bullet points to summary"
 2  prompt: |+
 3      Convert my short hand into a first-hand
 4      account of the meeting:
 5  
 6      <1>
 7  
 8      Summary:
 9  engine: "davinci-instruct-beta"
10  temperature: 0.7
11  max-tokens: 60
\end{verbatim}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgdab02c1},fragile]{Prompt YAML format Part 2}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
1  top-p: 1
2  frequency-penalty: 0.0
3  presence-penalty: 0.0
4  best-of: 1
5  stop-sequences:
6  - "\n\n"
7  conversation-mode: no
8  stitch-max: 0
\end{verbatim}

\begin{description}
\item[{stitch-max}] Keep stitching together until reaching this limit.
This allows a full response for answers which may need n*max-tokens to reach the stop-sequence.
\end{description}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgab4b096},fragile]{Prompt YAML format: Part 3}
 \begin{block}{\texttt{meeting-bullets-to-summary.prompt}}
\begin{verbatim}
1  vars:
2  - "notes"
3  examples:
4  - |+
5      Tom: Profits up 50%
6      Jane: New servers are online
7      Kjel: Need more time to fix software
8      Jane: Happy to help
9      Parkman: Beta testing almost done
\end{verbatim}
\end{block}
\end{frame}

\section{\texttt{semiosis}}
\label{sec:orgea42e8f}
\subsection{\texttt{pen.el}}
\label{sec:org8f808a0}
\begin{frame}[label={sec:orgdfe8b2f},fragile]{\texttt{Prompts as functions}}
 \begin{block}{\texttt{pen-generate-prompt-functions}}
Generate prompt functions for the files in the
prompts directory Function names are prefixed
with \texttt{pen-pf-} for easy searching.

\url{http://github.com/semiosis/prompts}
\end{block}
\end{frame}

\subsection{\texttt{examplary}}
\label{sec:org40d3ba5}
\begin{frame}[label={sec:orgc2fb74e},fragile]{\texttt{examplary}: examples as functions}
 An example-oriented DSL that can be used to
construct and compose NLP tasks.

Why is a DSL needed for this? Just to make the
code a little more terse.

\begin{block}{Regex}
\url{https://github.com/pemistahl/grex}

{\footnotesize
\begin{verbatim}
1  (def regex
2    "example 1\nexample2" "^example [12]$"
3    "example 2\nexample3" "^example [23]$"
4    "pi4\npi5" "^pi[45]$")
\end{verbatim}
}
\end{block}
\end{frame}

\begin{frame}[label={sec:org2b3ef09},fragile]{\texttt{examplary}: examples as functions}
 \begin{block}{Analogy}
{\footnotesize
\begin{verbatim}
 1  (def analogy
 2    ;; Each line is a training example.
 3    "NNs" "NNs are like genetic algorithms in
 4    that both are systems that learn from
 5    experience"
 6    "Social media" "Social media is like a
 7    market in that both are systems that
 8    coordinate the actions of many
 9    individuals.")
10  
11  (def field
12    "chemistry" "study of chemicals"
13    "biology" "study of living things")
\end{verbatim}
}
\end{block}
\end{frame}

\section{Demonstrations}
\label{sec:org2660e35}
\begin{frame}[label={sec:org89cc38e}]{Something funny}
\begin{block}{Vexate a simple instruction}
\begin{center}
\includegraphics[width=.9\linewidth]{./complicate.png}
\end{center}
\end{block}
\end{frame}

\begin{frame}[label={sec:org5a42cc2}]{Something funny}
\begin{block}{How to crack an egg}
\begin{center}
\includegraphics[width=.9\linewidth]{./crack-an-egg.png}
\end{center}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgf8b2049}]{Create a prompt}
\begin{block}{Ask the audience}
\begin{itemize}
\item What type of text to generate
\begin{itemize}
\item Could be code, prose, etc.
\end{itemize}
\end{itemize}
\end{block}
\end{frame}

\section{Appendix}
\label{sec:org4ac462c}
\subsection{Additional reading}
\label{sec:orgb3b1c52}
\begin{frame}[label={sec:org5efe502}]{Tutorials}
\begin{block}{Ruby}
{\footnotesize
\url{https://www.twilio.com/blog/generating-cooking-recipes-openai-gpt3-ruby}
}
\end{block}
\end{frame}
\end{document}